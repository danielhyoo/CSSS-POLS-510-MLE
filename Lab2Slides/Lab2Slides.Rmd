---
title: 'CSSS 510: Lab 2'
output:
  beamer_presentation
date: "2017-9-29"
subtitle: Introduction to Maximum Likelihood Estimation
---

# 0. Agenda

1. Simulating heteroskedastic normal data $\newline$

2. Fitting a model using the simulated data $\newline$

3. Calculating predicted values $\newline$ 

4. Fitting the heteroskedastic normal model using ML $\newline$

5. Simulating predicted values and confidence intervals 

# Simulating heteroskedastic normal data
Stochastic component:
$$y \sim N(\mu_{i}, \sigma_{i}^{2})$$

Systematic components:
$$\mu = \boldsymbol{x}_{i}\boldsymbol{\beta}$$

$$ \sigma_{i}^{2} = \text{exp}(\boldsymbol{z}_{i}\boldsymbol{\gamma})$$

# Simulating heteroskedastic normal data
\small 

1. Set the number of observations to 1500 ($n$)

2. Set a parameter vector for the mean (assume 2 covariates plus the constant) ($\boldsymbol{\beta}$)

3. Set a parameter vector for the variance (assume heteroskedasticity) ($\boldsymbol{\gamma}$)

4. Generate the constant and the covariates, length 1500 for each (draw from a uniform distribution) ($\boldsymbol{x}_{i}$, $\boldsymbol{z}_{i}$)

5. Create the systematic component for the mean ($\boldsymbol{x}_{i}\boldsymbol{\beta}$)

6. Create the systematic component for the variance (the same covariates affect mu and sigma) $\text{exp}(\boldsymbol{z}_{i}\boldsymbol{\gamma})$

7. Generate the response variable ($y_{i}$)

8. Save the data to a data frame 

9. Plot the data  

# Simulating heteroskedastic normal data
\scriptsize 
```{r}

rm(list=ls()) # Clear memory
set.seed(123456) # To reproduce random numbers
library(MASS) # Load packages
library(simcf)

n <- 1500 # Generate 1500 observations

beta <- c(0, 5, 15) # Set a parameter vector for the mean
# One for constant, one for covariate 1, one for covariate 2.

gamma <- c(1, 0, 3) # Set a parameter vector for the variance 
# Gamma estimate for covariate 2 is set to be 3, creating heteroskedasticity 

w0 <- rep(1, n) # Create the constant and covariates
w1 <- runif(n) # Length of each vector is 1500
w2 <- runif(n)
```

# Simulating heteroskedastic normal data
\scriptsize 
```{r}
x <- cbind(w0, w1, w2) # Create a matrix of the covariates

mu <- x%*%beta # Create the systemtic component for the mean

z <- x # i.e., same covariates affect mu and sigma
sigma2 <- exp(x%*%gamma) # Create the systematic component for the variance

# z is 1500 by 3 matrix, gamma is 3 by 1 matrix
#ith row of sigma 2 thus equals exp(1+0+w2_i*3). i.e., it is a function of w2

y <- mu + rnorm(n)*sqrt(sigma2) # Create the response variable

data <- cbind(y,w1,w2) # Save the data to a data frame
data <- as.data.frame(data)
names(data) <- c("y","w1","w2")

par(mfrow=c(1,3)) #Plot the data

#pdf("YvsW1.pdf")
plot(y=y,x=w1)
#dev.off()

#pdf("YvsW2.pdf")
plot(y=y,x=w2)
#dev.off()

#pdf("W1vsW2.pdf")
plot(y=w1,x=w2)
#dev.off()

```

# Fitting a model using the simulated data

1. Assume we don’t know the true value of the parameters and fit a model using least squares (use the lm() function and regress the response variable on the two covariates) $\newline$

2. Calculate and print the AIC


# Fitting a model using the simulated data
\scriptsize
```{r}

ls.result <- lm(y ~ w1 + w2) #Fit a linear model using the simulated data
print(summary(ls.result))
```

# Fitting a model using the simulated data
\scriptsize
```{r}

ls.aic <- AIC(ls.result) # Calculate and print the AIC
print(ls.aic)

```

# Calculating predicted values

## Scenario 1: Vary covariate 1

1. Create a data frame with a set of hypothetical scenarios for covariate 1 while keeping covariate 2 at its mean $\newline$

2. Calculate the predicted values using the predict() function $\newline$

3. Plot the predicted values

# Calculating predicted values - Scenario 1: Vary covariate 1
\scriptsize
```{r}
# Calculate predicted values using predict()
# Start by calculating P(Y|w1) for different w1 values
w1range <- seq(0:20)/20  # Set as necessary
# Set up a dataframe with the hypothetical scenarios 
# (varied w1, all else equal)
baseline <- c(mean(w1), mean(w2))  # Set as necessary
xhypo <- matrix(baseline, nrow=length(w1range), ncol=2, byrow= TRUE) 
# Set ncol to # of x's
# same as: xhypo <- 
# matrix(rep(baseline,21), nrow=length(w1range), ncol=2, byrow= TRUE)  
xhypo <- as.data.frame(xhypo)
names(xhypo) <- c("w1","w2")                                          
xhypo[,1] <- w1range 
# Scenarios: Changing values in the first column
# Keeping second column values at the mean of w2. 
head(xhypo)
```

# Calculating predicted values - Scenario 1: Vary covariate 1
\scriptsize
```{r}

# Calculate Predicted Y using predict()
simls.w1<-predict(ls.result,newdata = xhypo,interval="prediction",level=0.95)
head(simls.w1)

# Plot them
yplot <- simls.w1
xplot <- cbind(w1range,w1range,w1range) 
# need to have the same dimension [21,3]
#pdf("homoYvsW1.pdf")
```

# Calculating predicted values - Scenario 1: Vary covariate 1
\tiny
```{r}
matplot(y=yplot, x=xplot, type="l", lty=c("solid","dashed","dashed"), 
        col=c("black"), xlab = "w1", ylab = "Predicted Y")
#dev.off()
```

# Calculating predicted values 
## Scenario 2: Vary covariate 2

1. Create a data frame with a set of hypothetical scenarios for covariate 2 while keeping covariate 1 at its mean $\newline$

2. Calculate the predicted values using the predict() function $\newline$

3. Plot the predicted values

# Calculating predicted values - Scenario 2: Vary covariate 2
\scriptsize
```{r}
# Calculate predicted values using predict()

# Start by calculating P(Y|w1) for different w1 values
w2range <- seq(0:20)/20 # Set as necessary

# Set up a dataframe with the hypothetical scenarios 
# (varied w1, all else equal)
baseline <- c(mean(w1), mean(w2)) # Set as necessary
xhypo <- matrix(baseline, nrow=length(w2range), ncol=2, byrow= TRUE)  
xhypo <- as.data.frame(xhypo) # Set ncol to # of x's
names(xhypo) <- c("w1","w2") # Set by user
xhypo[,2] <- w1range # Change as necessary

# Calculate Predicted Y using predict()
simls.w2 <- predict(ls.result,newdata=xhypo,interval="prediction",level=0.95)

# Plot them
yplot <- simls.w2
xplot <- cbind(w2range,w2range,w2range)
#pdf("homoYvsW2.pdf")
```

# Calculating predicted values - Scenario 2: Vary covariate 2
\tiny
```{r}
matplot(y=yplot, x=xplot, type="l", lty=c("solid","dashed","dashed"), col=c("black"),
        xlab = "w1", ylab = "Predicted Y")
#dev.off()

```

# Fitting the heteroskedastic normal model using ML

1. Create the input matrices (the two covariates)

2. Write a likelihood function for the heteroskedastic normal model 

3. Find the MLEs using the optim() function

4. Extract the point estimates

5. Compute the standard errors

6. Compare with the least squares estimates

7. Find the log likelihood at its maximum

8. Compute the AIC

9. Simulate the results by drawing from the model’s predictive distribution 

10. Separate the simulated betas from the simulated gammas

# Fitting the heteroskedastic normal model using ML
$\newline$
\scriptsize
```{r}

# A likelihood function for ML heteroskedastic Normal
llk.hetnormlin <- function(param,y,x,z) {
  x <- as.matrix(x)		#x as a matrix
  z <- as.matrix(z)		#z as a matrix
  os <- rep(1,nrow(x))	#1 for the intercept
  x <- cbind(os,x)		#combine
  z <- cbind(os,z)
  b <- param[ 1 : ncol(x) ] 
  # i.e., the first three spaces in the param vector
  g <- param[ (ncol(x)+1) : (ncol(x) + ncol(z)) ] 
  # i.e., the three remaining spaces 
  xb <- x%*%b # systematic components for the mean
  s2 <- exp(z%*%g) # systematic components for the variance
  
  sum(0.5*(log(s2)+(y-xb)^2/s2)) 
  # "optim" command minimizes a function by default. 
  # Minimalization of -lnL is the same as maximization of lnL
  # so we will put -lnL(param|y) here
 
  #-sum(0.5*(log(s2)+(y-xb)^2/s2)) 
  # Alternativly, you can use lnL(param|y) and set optim to be a maximizer 
  }
```

# Fitting the heteroskedastic normal model using ML
\scriptsize
```{r}
# Create input matrices
xcovariates <- cbind(w1,w2)
zcovariates <- cbind(w1,w2)

# initial guesses of beta0, beta1, ..., gamma0, gamma1, ...
# we need one entry per parameter, in order!
stval <- c(0,0,0,0,0,0) # also include beta and gamma estiamtes for constants 

help(optim)

# Run ML, get the output we need
hetnorm.result <- 
  optim(stval,llk.hetnormlin,method="BFGS",
        hessian=T,y=y,x=xcovariates,z=zcovariates) 
# by default, calls minimizer procedure. 
# you can make optim a maximizer by adding control=list(fnscale=-1)
```

# Fitting the heteroskedastic normal model using ML
\scriptsize
```{r}
pe <- hetnorm.result$par   # point estimates
pe

vc <- solve(hetnorm.result$hessian)  
# 6x6 var-cov matrix (allows to compute standard errors)
round(vc,5)

se <- sqrt(diag(vc))    # standard errors
# the ML standard errors are the square roots of the diagonal of the Hessian 
# or inverse of the matrix of second derivaties
se
```

# Fitting the heteroskedastic normal model using ML
\scriptsize
```{r}
mle.result<-round(cbind(pe[1:3], se[1:3]),2) # see pe and se 
colnames(mle.result)<-c("Estimate", "Std.Error")
rownames(mle.result)<-c("(Intercept)", "w1","w2" )
mle.result

round(summary(ls.result)$coefficients[,c(1,2)],2) #compare with the ls result


ll <- -hetnorm.result$value  
# likelihood at maximum, no need to  
# have a negative sign if you set optime to be a maximizer. 
ll
```

# Fitting the heteroskedastic normal model using ML
\scriptsize
```{r}
#The AIC is the deviance or -2*ll at its max plus 2*number of parameters or the dimension
hetnorm.aic <- 2*length(stval) - 2*ll  
# first component to penalizing the number of parameters 
# (i.e., the loss of degree of freedom). Lower aic is better

print(hetnorm.aic)

# remember AIC from LS fit? 
print(ls.aic)
```

# Simulating predicted values and confidence intervals

## Scenario 1: Vary covariate 1

1. Create a data frame with a set of hypothetical scenarios for covariate 1 while keeping covariate 2 at its mean $\newline$

2. Simulate the predicted values and the confidence intervals using simcf $\newline$

3. Plot the results

# Simulating predicted values and confidence intervals - Scenario 1: Vary covariate 1
\scriptsize
```{r}
# Simulate results by drawing from the model predictive distribution
sims <- 10000
simparam <- mvrnorm(sims,pe,vc) 
# draw parameters store them in 10000x6 matrix. 
# We assume that parameter estimates are distributed 
# according to a multivariate normal distribution with population mean pe 
# and population variance-covariance matrix vc.

# Separate into the simulated betas and simulated gammas
simbetas <- simparam[,1:(ncol(xcovariates)+1)] 
# first three columns store simulated beta coefficients 
simgammas <- simparam[,(ncol(simbetas)+1):ncol(simparam)] 
# then simulated gamma coefficients

# Put our models in "formula" form
model <- (y ~ w1 + w2)
varmodel <- (y ~ w1 + w2)

# Scenario 1:  Vary w1

# Start by calculating P(Y|w1) for different w1 values
w1range <- seq(0:20)/20
```

# Simulating predicted values and confidence intervals - Scenario 1: Vary covariate 1
\scriptsize
```{r}
# Set up a matrix with the hypothetical scenarios (varied w1, all else equal)
xhypo <- cfMake(model, data, nscen = length(w1range)) 
# creating a set of scenarios 
for (i in 1:length(w1range)) {
  xhypo <- cfChange(xhypo, "w1", x=w1range[i], scen=i) 
  # change the values of the variables of your interest, set others at the mean
}
zhypo <- cfMake(varmodel, data, nscen = length(w1range))

for (i in 1:length(w1range)) {
  zhypo <- cfChange(zhypo, "w1", x=w1range[i], scen=i) 
}
# Simulate the predicted Y's and CI's
simres.w1 <- hetnormsimpv(xhypo,simbetas,
                          zhypo,simgammas,
                          ci=0.95,
                          constant=1,varconstant=1)

#simy<-rnorm(sims)*sqrt(simsigma2)+ simmu
# Plot them
yplot <- cbind(simres.w1$pe, simres.w1$lower, simres.w1$upper)
xplot <- cbind(w1range,w1range,w1range)
```

# Simulating predicted values and confidence intervals - Scenario 1: Vary covariate 1
\tiny
```{r}
#pdf("heteroYvsW1.pdf")
matplot(y=yplot, x=xplot, type="l", lty=c("solid","dashed","dashed"),
        col=c("black"), xlab = "w1", ylab = "Predicted Y")
#dev.off()
```

# Simulating predicted values and confidence intervals - Scenario 2: Vary covariate 2

1. Create a data frame with a set of hypothetical scenarios for covariate 2 while keeping covariate 1 at its mean $\newline$

2. Simulate the predicted values and the confidence intervals using simcf $\newline$

3. Plot the results

# Simulating predicted values and confidence intervals - Scenario 2: Vary covariate 2
\scriptsize
```{r}
# Start by calculating P(Y|w2) for different w1 values
w2range <- seq(0:20)/20

# Set up a matrix with the hypothetical scenarios (varied w1, all else equal)
xhypo <- cfMake(model, data, nscen = length(w2range))
for (i in 1:length(w2range)) {
  xhypo <- cfChange(xhypo, "w2", x=w2range[i], scen=i) 
}

zhypo <- cfMake(varmodel, data, nscen = length(w2range))
for (i in 1:length(w2range)) {
  zhypo <- cfChange(zhypo, "w2", x=w2range[i], scen=i) 
}

# Simulate the predicted Y's and CI's
simres.w2 <- hetnormsimpv(xhypo,simbetas,
                          zhypo,simgammas,
                          ci=0.95,
                          constant=1,varconstant=1)
# Plot them
yplot <- cbind(simres.w2$pe, simres.w2$lower, simres.w2$upper)
xplot <- cbind(w1range,w1range,w1range)
#pdf("heteroYvsW2.pdf")
```
# Simulating predicted values and confidence intervals - Scenario 2: Vary covariate 2
\scriptsize
```{r}
matplot(y=yplot, x=xplot, type="l", lty=c("solid","dashed","dashed"),
        col=c("black"), xlab = "w2", ylab = "Predicted Y")
#dev.off()
```


